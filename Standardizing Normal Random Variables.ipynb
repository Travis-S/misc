{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Problem Statement#\n",
    "Given a random variable $X \\sim \\mathcal{N}(\\mu, \\sigma^{2})$, how is it that the random variable $Z = \\frac{X-\\mu}{\\sigma}$ is $\\mathcal{N}(0, 1)$? It is this question we are going to answer.\n",
    "\n",
    "**Intuitive Justification**\n",
    "\n",
    "Notice that if $\\langle X \\rangle = \\mu$, then $\\langle Z \\rangle = \\frac{\\langle X \\rangle - \\mu}{\\sigma^{2}} = 0$. Further, we have $\\langle Z^{2} \\rangle = \\frac{1}{\\sigma^{2}}\\langle (X-\\mu)^{2}\\rangle = \\frac{\\langle X^{2} \\rangle - 2 \\mu \\langle X \\rangle + \\mu^{2}}{\\sigma^{2}} = \\frac{\\langle X^{2} - \\mu^{2}\\rangle}{\\sigma^{2}} = \\frac{Var(X)}{\\sigma^{2}} = 1$.\n",
    "\n",
    "However, just because the expected value and variance of $Z$ match the standard normal distribution does not necessarily mean the _distribution_ of $Z$ is $\\mathcal{N}(0,1)$. So while the above provides some justification, we have more work to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The Main Technique - Characteristic Functions#\n",
    "\n",
    "To demonstrate the result, we will rely on the characteristic function. Given a probability measure $\\mu(x)$, the characteristic function $\\psi(t)$ is defined as\n",
    "\n",
    "$$\\psi(t) = \\langle e^{itX}\\rangle = \\int e^{itx}~d\\mu(x)$$\n",
    "\n",
    "Assuming $\\mu(x) = p(x)~dx$ for some probability density function (pdf) $p$, we have\n",
    "\n",
    "$$\\psi_{X}(t) = \\int p(x)e^{itx}~dx$$\n",
    "\n",
    "You may recognize this as the _Fourier transform_ of the pdf. Hence, we have little to be worried about, since Fourier transforms occur in many diverse branches of mathematics, and are well-studied. Note: We use the subscript $_{X}$ to denote which random variable the characteristic function is representing.\n",
    "\n",
    "\n",
    "**Joint pdfs $p(x,y)$**\n",
    "\n",
    "Eventually, we will need to consider joint pdfs $p(x,y)$. Let's show a useful result about characteristic functions when the random variables $X$ and $Y$ are independent and we are considering quanties of the form $X + Y$.\n",
    "\n",
    "By definition, the characteristic function of $\\psi(t)$ is given as \n",
    "\n",
    "$$\\psi_{X+Y}(t) = \\int p(x, y)e^{it(x+y)}~dx~dy$$\n",
    "\n",
    "Now, under the assumption $X$ and $Y$ are independent, then $p(x, y) = a(x)b(y)$ for some pdfs $a$ and $b$. Plugging this in above, we see\n",
    "\n",
    "$$\\boxed{\\psi_{X+Y}(t) = \\int a(x)e^{itx}~dx \\int b(y)e^{ity}~dy = \\psi_{X}(t)\\psi_{Y}(t)}$$\n",
    "\n",
    "Thus, if $X$ and $Y$ are independent random variables, then the characteristic function of their sum is simply the product of their characterstic functions.\n",
    "\n",
    "**Rescaling**\n",
    "\n",
    "Another result we will need is to consider random variables of the form $X/c$ for some constant $c$. Plugging this into the definition gives\n",
    "\n",
    "$$\\boxed{\\psi_{X/c}(t) = \\int p(x)e^{it(x/c)}~dx = \\int p(x)e^{i(t/c)x} = \\psi_{X}(t/c)}$$\n",
    "\n",
    "That is, the characteristic function of a (constant) rescaled random variable is simply the characteristic function for that random variable evaluated at a different point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#First step: $\\psi_{X}$ for $X\\sim \\mathcal{N}(\\mu,\\sigma^{2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will simply compute the characterstic function for a normally distributed random variable. That way we have a formula to compare our results to.\n",
    "\n",
    "By definition, we have\n",
    "\n",
    "$$\\psi_{X}(t) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\int e^{-(x-\\mu)^{2}/2\\sigma^{2}}e^{itx}~dx$$\n",
    "\n",
    "Making a change of variables $u = x-\\mu$ gives\n",
    "\n",
    "$$\\psi_{X}(t) = \\frac{e^{it\\mu}}{\\sigma\\sqrt{2\\pi}}\\int e^{-u^{2}/2\\sigma^{2}}e^{itu}~du$$\n",
    "\n",
    "We then substitute $x  = u /\\sigma$:\n",
    "\n",
    "$$\\psi_{X}(t) = \\frac{e^{it\\mu}}{\\sqrt{2\\pi}}\\int e^{-x^{2}/2}e^{i\\sigma tx}~dx$$\n",
    "\n",
    "To do this integral rigoriously, we would introduce complex variables. Instead, we will ask what happens if we just try to compute it directly. To do this, we complete the square by writing\n",
    "\n",
    "$$(x - i\\sigma t)^{2}/2 = x^{2}/2 -i\\sigma t x - (\\sigma t)^{2}/2 \\implies e^{-x^{2}/2 + i\\sigma tx} = e^{-(x-it\\sigma)^{2}/2}e^{-(\\sigma t)^{2}/2}$$ \n",
    "\n",
    "Thus the characteristic function becomes\n",
    "\n",
    "$$\\psi_{X}(t) = \\frac{e^{it\\mu - \\sigma^{2}t^{2}/2}}{\\sqrt{2\\pi}}\\int e^{-(x-i\\sigma t)^{2}}~dx$$\n",
    "\n",
    "Again, a proper treatment would involve doing a complex integral; instead, we make a substitution $u = x - i\\sigma t$ to give\n",
    "\n",
    "$$\\boxed{\\psi_{X}(t) = \\frac{e^{it\\mu - \\sigma^{2}t^{2}/2}}{\\sqrt{2\\pi}}\\int e^{-u^{2}}~du = e^{it\\mu - \\sigma^{2}t^{2}/2}}$$\n",
    "\n",
    "Thus the characteristic function for a single Gaussian random variable is an oscillating function with a Gaussian envelope.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Step 2: Computing $\\psi_{X-\\mu}$#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have $\\psi_{X}(t)$, let's compute $\\psi_{X-\\mu}(t)$. How do we do so? One way is to observe that $\\mu$ is a constant, and that constants are special cases of random variables. Further, because $\\mu$ is a constant, it is obviously independent of $X$ statistically. How do we factor the joint pdf $p(X,\\mu)$? Although it sounds like a slight trick, let's observe that we can write\n",
    "\n",
    "$$\\mu = \\int \\delta(y - \\mu)~dy$$\n",
    "\n",
    "where $\\delta(y-\\mu)$ is the [Dirac delta function](https://en.wikipedia.org/wiki/Dirac_delta_function). This suggests we could write $-\\mu$ as $\\int \\delta(y + \\mu)~dy$, giving\n",
    "\n",
    "$$p(x, \\mu) = \\mathcal{N}(\\mu,\\sigma^{2})(x)\\delta(y+\\mu)$$\n",
    "\n",
    "Applying our result for $\\psi_{X+Y}$ for two indpendent random variables, we have\n",
    "\n",
    "$$\\boxed{\\psi_{X-\\mu}(t) = \\psi_{X}(t)\\int \\delta(y+\\mu)e^{ity}~dy = e^{it\\mu - \\sigma^{2}t^{2}/2}\\times e^{-it\\mu} = e^{-\\sigma^{2}t^{2}/2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Step 3: Computing $\\psi_{(X-\\mu)/\\sigma}$#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now have $\\psi_{X-\\mu}$, all that remains is to divide by $\\sigma$. Using the other result above regarding $\\psi_{X/c}(t) = \\psi_{X}(t/c)$, we find\n",
    "\n",
    "$$\\boxed{\\psi_{(X-\\mu)/\\sigma}(t) = \\psi_{X-\\mu}(t/\\sigma) = e^{-\\sigma^{2}(t/\\sigma)^{2}/2} = e^{-t^{2}/2}}$$\n",
    "\n",
    "Observing the function on the right is the characteristic function for a random variable distributed as $\\mathcal{N}(0, 1)$, we conclude\n",
    "\n",
    "$$\\psi_{(X-\\mu)/\\sigma}(t) = \\psi_{Z}(t)~~~~Z\\sim \\mathcal{N}(0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Step 4: Establishing the Equivalence#\n",
    "\n",
    "We have shown the characteristic function for $\\frac{X-\\mu}{\\sigma}$, where $X\\sim \\mathcal{N}(\\mu, \\sigma^{2})$ is the characteristic function for a random variable $Z \\sim \\mathcal{N}(0, 1)$. Let's now show that the pdfs are equal by taking an inverse Fourier transform:\n",
    "\n",
    "$$p((X-\\mu)/\\sigma) = \\int e^{-itx}\\psi_{(X-\\mu)/\\sigma}(t)~dt = \\int e^{-itx}\\psi_{Z}(t)~dt = e^{-x^{2}/2} $$\n",
    "\n",
    "where the last equality follows because $Z \\sim \\mathcal{N}(0, 1)$. Hence, because the pdf of $\\frac{X-\\mu}{\\sigma}$ is $\\mathcal{N}(0, 1)$, we have demonstrated what we set out to show:\n",
    "\n",
    "\n",
    "> Given a random variable $X \\sim \\mathcal{N}(\\mu, \\sigma^{2})$, the random variable $Z = \\frac{X-\\mu}{\\sigma}$ has the standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
